# -*- coding: utf-8 -*-
"""CNNword2vecClassLyrics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18bZGc8mQnSojiIAE1odezD_HYt6e9aNv
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)


import os
#if you wish to run this locally, uncomment this code!
#from os.path import dirname
#curr = os.getcwd()
#directory = dirname(curr)
#print(directory)
#with open(directory+"/content/lyrics.csv") as f:
with open("/content/lyrics.csv") as f: #comment out this line if you are running this locally 
  df = pd.read_csv(f, names=['index', 'song', 'year', 'artist', 'genre', 'lyrics'], dtype={'lyrics': str})
  #some preprocessing steps on lyrics: lower their case, and remove useless words/symbols which recur quite often
  df['lyrics'] = df['lyrics'].str.lower()
  df['lyrics'] = df['lyrics'].str.strip('[]')
  df['lyrics'] = df['lyrics'].str.strip('()')
  df["lyrics"] = df['lyrics'].str.replace('chorus','')
  df["lyrics"] = df['lyrics'].str.replace('verse','')
  df["lyrics"] = df['lyrics'].str.replace('intro','')
  lyrics = df['lyrics'].to_dict()
  genres = df['genre'].to_dict()
            
#now we only consider 'valid' lyrics, that is to say, only those lyrics that have actually
#more than 10 words and are NOT empty (there are empty lyrics in the dataset)
valid_lyrics = {}
valid_genres = {}
for key in lyrics:
    if len(str(lyrics[key]))>10:
        valid_lyrics[key] = lyrics[key]
        valid_genres[key] = genres[key]

print("\nRemaining valid lyrics and corresponding genres:\n")
print(len(valid_lyrics))
print(len(valid_genres))

#now a preprocessing step to tokenize, remove punctuation and stopwords from each lyric
preprocessed_lyrics = {}
import nltk
nltk.download('stopwords')
from nltk.tokenize import RegexpTokenizer
from nltk.corpus import stopwords
tokenizer = RegexpTokenizer(r'\w+')
stop_words = set(stopwords.words('english'))
for key in valid_lyrics: #for each lyric, tokenize it, remove punctuation and remove stopwords
    tokenized_lyric = tokenizer.tokenize(str(valid_lyrics[key]))
    preprocessed_lyrics[key] = []
    for word in tokenized_lyric:
        if word not in stop_words:
            if word not in preprocessed_lyrics[key]:
                preprocessed_lyrics[key].append(word)
#we now have for each lyric, a bag of words for the lyric

#these are all the genres we have
genres_final = {}
for g in valid_genres:
    if valid_genres[g] not in genres_final:
        genres_final[valid_genres[g]] = [valid_genres[g]]

print("\nClasses in original dataset:\n")
for key in genres_final:
  print(key)

#we will not consider genres such as "Other" or "Not available", we consider them
#as unclassified songs
#we only deal with these 5 classes
genre2lyrics = {}
genre2lyrics["Rock"] = []
genre2lyrics["Hip-Hop"] = []
genre2lyrics["Electronic"] = []
genre2lyrics["Jazz"] = []
genre2lyrics["Country"] = []
for key in preprocessed_lyrics:
    if valid_genres[key] in genre2lyrics:
        genre2lyrics[valid_genres[key]].append(preprocessed_lyrics[key])
print("\nClasses in our dataset:\n")
for key in genre2lyrics:
    print(key, len(genre2lyrics[key]))

#notice that we have far more lyrics/songs for Rock class and Hip Hop class with respect
#to the other classes, so we need to balance the dataset and we can do this by
#selecting a certain number of songs from each class, same number for each of them

#to make our dataset more balanced, we arbitrarily select
#only 1500 lyrics from each of the five genres, and work with them.
#if you wish to work with a larger dataset to have better results,
#set the value from 1500 to a higher 5000, 6000 or 7000 maximum - and the dataset is still balanced with
#these values.
genre2lyrics["Rock"] = genre2lyrics["Rock"][:1500] #also tried with [:5000]
genre2lyrics["Hip-Hop"] = genre2lyrics["Hip-Hop"][:1500] #also tried with [:5000]
genre2lyrics["Electronic"] = genre2lyrics["Electronic"][:1500] #also tried with [:5000]
genre2lyrics["Jazz"] = genre2lyrics["Jazz"][:1500] #also tried with [:5000]
genre2lyrics["Country"] = genre2lyrics["Country"][:1500] #also tried with [:5000]
texts = []
labels = []
for genre in genre2lyrics:
  for lyric in genre2lyrics[genre]:
    texts.append(lyric)
    labels.append(genre)

#now we split it into train, development and test
from sklearn.model_selection import train_test_split
rest_texts, test_texts, rest_labels, test_labels = train_test_split(texts, labels, test_size=0.1, random_state=1)
train_texts, dev_texts, train_labels, dev_labels = train_test_split(rest_texts, rest_labels, test_size=0.1, random_state=1)

print("Train size:", len(train_texts))
print("Dev size:", len(dev_texts)) #not actually used here
print("Test size:", len(test_texts))
#and now we get the number of labels with corresponding indexes
target_names = list(set(labels))
label2idx = {label: idx for idx, label in enumerate(target_names)}
print(label2idx)
print(type(train_texts))
print(type(train_labels))

#END OF THE PREPROCESSING STEP

#BUILD VOCAB: WORD2VEC MODEL
#this is to exploit a word2vec embedding 
for_vocab = train_texts + dev_texts
import gensim
from gensim.models import Word2Vec 
#about the parameters here: min_count = 1 -> take into account each word no matter how many times it appears in the corpus
#size = 100 -> output vector of dimension = 100 for each word
#window = 5 -> for each word being processed by the network, only take into account words that are in a range of distance of max. 5 from
#the word in the lyric
#sg = 1 -> exploit the CBOW model
#to exploit the skip-gram model, set the values to:
#window = 10 (default for skip-gram)
#sg = 2 -> skip-gram model
w2v = gensim.models.Word2Vec(for_vocab, min_count = 1, size = 100, 
                                             window = 5, sg = 1) 
print(w2v)
words_in_vocab = []
for word in w2v.wv.vocab:
  words_in_vocab.append(word)
word = words_in_vocab[1]
embedded_word = w2v.wv[word]
print(word)
print(embedded_word)
print(len(embedded_word))
n_words_in_vocab = len(words_in_vocab)
vectors_size = len(embedded_word)
print(n_words_in_vocab)
print(vectors_size)
#END OF WORD2VEC MODEL STEP

#CREATING THE PYTORCH DATASET STEP
#now we are going to create a dataset in Pytorch
# indx = w2v.wv.vocab[word].index
#now that we have our vocabulary, next point is to encode our training and test datasets
#to create a dataset which can be exploited via Pytorch
to_train = train_texts + dev_texts
to_label = train_labels + dev_labels
def encode_lyrics(dataset):
  lyrics = []
  for lyric in dataset:
    ly = []
    for word in lyric:
      try:
        indx = w2v.wv.vocab[word].index
      except:
        indx = 0
      ly.append(indx)
    lyrics.append(ly)
  return lyrics


def encode_labels(dataset):
  labels = []
  for genre in dataset:
    labels.append(label2idx[genre])
  return np.asarray(labels)

y_training = encode_labels(to_label)
print(y_training[1])
X_training = encode_lyrics(to_train)
print(X_training[1])

#lyrics have different length, so we decide to either pad the shorter ones or cut the longer ones
#to a prefixed length of 100 words
def padding(dataset, l):
  for lyric in dataset:
    if len(lyric) < l:
      while len(lyric)!=l:
        lyric.append(0)
    else:
      while len(lyric) > l:
        lyric.pop()
  return dataset

X_training = padding(X_training, 100)
for ly in X_training:
  if len(ly) > 100:
    print(len(ly))
  if len(ly) < 100:
    print(len(ly))
print(y_training[1])
print(X_training[1])

#now we can create the dataset and the dataloader for Pytorch
import torch
from torch.utils.data import TensorDataset, DataLoader

#Tensor Dataset
train_data = TensorDataset(torch.LongTensor(X_training), torch.from_numpy(y_training))
print(train_data)
print(train_data[1])
#DataLoader
train_loader = DataLoader(train_data, shuffle=True, batch_size=50)
print(train_loader)
#END OF PYTORCH DATASET STEP

#BUILDING UP THE CNN STEP
#now we build up our neural network
import torch
from torch import nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.filters = 100
        self.output = len(label2idx)
        #embedding layer for the nn
        self.n_words_in_vocab = n_words_in_vocab
        self.vectors_size = vectors_size
        self.embedding = nn.Embedding(self.n_words_in_vocab, self.vectors_size)
        self.embedding.weight = nn.Parameter(torch.from_numpy(w2v.wv.vectors))
        #freeze the embeddings, they will only be a lookup table
        self.embedding.requires_grad = False
        #convolutional layer
        self.conv = nn.Conv2d(1, self.filters, (self.output,self.vectors_size))
        #FULLY CONNECTED LAYER:
        self.fc1 = nn.Linear(self.filters, self.output) #desired number of output layers = 5, it's the number of genres we have!
        self.softmax = nn.Softmax(1)

    def forward(self, x):
        x = self.embedding(x)
        x = x.unsqueeze(1) #to have an input channel dimension=1 that is the one that conv layer expects,
        #so we are basically making a 1-dimensional cross-correlation
        x = F.relu(self.conv(x)).squeeze(3) #pooling will expect a 4-dimensional input
        x = F.max_pool1d(x, x.size(2))  
        x = x.view(x.shape[0], -1) #flatten the output of pooling to provide the final fc layer the expected input
        #apply dropout ONLY IF NOT TRAINING
        x = F.dropout(x, training = self.training)
        x = self.fc1(x)
        return self.softmax(x)
#END OF BUILDING UP CNN STEP

#INSTANTIATING THE CNN STEP
#enabling GPU
use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
from torch import nn, optim
net = Net()

net.to(device)

loss = nn.CrossEntropyLoss()
opt = optim.Adam(params=net.parameters(), lr = 0.001)

print(net)

net = net.float()

#DEFINING THE TRAINING STEP
#training the CNN
def train_step(x, y):
  net.train()
  y_pred = net(x)
  loss_epoch = loss(y_pred, y)
  loss_epoch.backward()
  opt.step()
  opt.zero_grad()

#TRAINING STEP
import torch
from tqdm import tqdm_notebook as tqdm
for epoch in tqdm(range(20)):
  net.train()
  for Xb, yb in train_loader:
    Xb = Xb.to(device) #move into device 
    yb = yb.to(device) #move into device 
    train_step(Xb, yb)

#BUILDING THE TEST DATASET FOR PYTORCH STEP
#now building the test_dataset
y_testing = encode_labels(test_labels)
X_test = encode_lyrics(test_texts)
X_test = padding(X_test, 100)
print(y_testing[1])
print(X_test[1])

#Tensor Dataset
test_data = TensorDataset(torch.LongTensor(X_test), torch.from_numpy(y_testing))
print(test_data)
print(test_data[1])
#DataLoader
test_loader = DataLoader(test_data, shuffle=True, batch_size=50)
print(test_loader)
#END OF BUILDING THE TEST DATASET FOR PYTORCH STEP

#EVALUATION OF THE NETWORK
#now evaluating the performances on the test_dataset
with torch.no_grad():
  Y_pred = []
  Y_true = []
  net.eval()
  for Xb, yb in test_loader:
    Xb = Xb.to(device)
    y_pred = net(Xb)
    yb = yb.to(device)
    correct = (y_pred.max(dim=1)[1] == yb)
    Y_pred.append(y_pred.max(dim=1)[1].cpu())
    Y_true.append(yb.cpu())
  print(torch.mean(correct.float()).item())

from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report
print(confusion_matrix(torch.cat(Y_true), torch.cat(Y_pred)))

print("\nTest performance:", precision_recall_fscore_support(torch.cat(Y_true), torch.cat(Y_pred), average="micro"))


print(classification_report(torch.cat(Y_true), torch.cat(Y_pred), target_names=target_names))